{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import os \n",
    "import math\n",
    "import gzip\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from progressbar import ProgressBar\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC curves based on the metrics \n",
    "\n",
    "Using the false and true positive rates stored in the metrics file, we can plot the ROC curves; use the different functions depending on whether the measure is IC-based, edge-based or direct groupwise (as results are slightly different formats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to contain ROC curves\n",
    "if not os.path.exists('ROCfigures'):\n",
    "    os.makedirs('ROCfigures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('ROCfigures/ICPairwise'):\n",
    "    os.makedirs('ROCfigures/ICPairwise')\n",
    "\n",
    "def plotROC_ic(metrics_file):\n",
    "    \n",
    "    ''' For IC-based similarity measures.\n",
    "    \n",
    "    Depending on the format of your SML computation results, this function\n",
    "    may need adapting to suit. \n",
    "    Due to splitting files to lessen\n",
    "    the computational demands in our run, we had slightly different results \n",
    "    formats hence 3 separate functions with different naming methods '''\n",
    "    \n",
    "    data = pd.read_csv(metrics_file, sep='\\t')\n",
    "    \n",
    "    data = data.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    for i in range(len(data.index)):\n",
    "        \n",
    "        ic_name = metrics_file.replace('ROCmetrics/metrics_', '').replace('_indirect_groupwise_combinations.tsv', '')\n",
    "        measure_name = data.loc[i, 'measure'] # for plot naming later \n",
    "        \n",
    "        fpr = data.loc[i, 'fpr'].strip('[').strip(']').strip(' ').split(',') # these are saved as strings so have to clean\n",
    "        tpr = data.loc[i, 'tpr'].strip('[').strip(']').strip(' ').split(',')\n",
    "        \n",
    "        x = [ float(i) for i in fpr ]\n",
    "        y = [ float(i) for i in tpr ]\n",
    "        \n",
    "        # plot the curve \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(x, y, linestyle='--', marker='o', color='orange', lw = 2, label='ROC curve', clip_on=False)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('{} IC-based {} ROC curve,'.format(ic_name, measure_name) + ' AUC = %.4f'%metrics.auc(x, y))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "                  \n",
    "        plt.savefig('ROCfigures/ICPairwise/ROC_{}_{}.png'.format(ic_name, measure_name)) \n",
    "        \n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('ROCfigures/EdgePairwise'):\n",
    "    os.makedirs('ROCfigures/EdgePairwise')\n",
    "    \n",
    "def plotROC_edge(metrics_file):\n",
    "    \n",
    "    data = pd.read_csv(metrics_file, sep='\\t')\n",
    "    \n",
    "    data = data.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    for i in range(len(data.index)):\n",
    "        \n",
    "        measure_name = data.loc[i, 'measure'] \n",
    "        \n",
    "        \n",
    "        fpr = data.loc[i, 'fpr'].strip('[').strip(']').strip(' ').split(',')\n",
    "        tpr = data.loc[i, 'tpr'].strip('[').strip(']').strip(' ').split(',')\n",
    "        \n",
    "        x = [ float(i) for i in fpr ]\n",
    "        y = [ float(i) for i in tpr ]\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(x, y, linestyle='--', marker='o', color='orange', lw = 2, label='ROC curve', clip_on=False)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Edge-based {} ROC curve,'.format(measure_name) + ' AUC = %.4f'%metrics.auc(x, y))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "                  \n",
    "        plt.savefig('ROCfigures/EdgePairwise/ROC_{}.png'.format(measure_name)) \n",
    "        \n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('ROCfigures/DirectGroupwise'):\n",
    "    os.makedirs('ROCfigures/DirectGroupwise')\n",
    "\n",
    "def plotROC_direct(metrics_file):\n",
    "    \n",
    "    data = pd.read_csv(metrics_file, sep='\\t')\n",
    "    \n",
    "    data = data.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    # dictionary for replacing bad measure names\n",
    "    measures_revised = pd.read_csv('GenerateXML/measures_revised.csv', sep=',')\n",
    "    measures_dict = dict(zip(measures_revised['ID'], measures_revised['Flag']))\n",
    "    \n",
    "    for i in range(len(data.index)):\n",
    "        \n",
    "        measure_name = measures_dict.get(data.loc[i, 'measure'])        \n",
    "        measure_name = measure_name.replace('SIM_', '')\n",
    "        \n",
    "        fpr = data.loc[i, 'fpr'].strip('[').strip(']').strip(' ').split(',')\n",
    "        tpr = data.loc[i, 'tpr'].strip('[').strip(']').strip(' ').split(',')\n",
    "        \n",
    "        x = [ float(i) for i in fpr ]\n",
    "        y = [ float(i) for i in tpr ]\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(x, y, linestyle='--', marker='o', color='orange', lw = 2, label='ROC curve', clip_on=False)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Direct {} ROC curve,'.format(measure_name) + ' AUC = %.4f'%metrics.auc(x, y))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "                  \n",
    "        plt.savefig('ROCfigures/DirectGroupwise/ROC_{}.png'.format(measure_name)) \n",
    "        \n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen below, we ended up splitting IC-based measures. \n",
    "Here, we used a single IC measure, with all available suitable pairwise and groupwise measures, in each SML run. \n",
    "All direct groupwise, and non-IC based pairwise with groupwise, were completed in single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on all direct groupwise \n",
    "\n",
    "plotROC_direct('ROCmetrics/metrics_direct_groupwise_combinations.tsv')\n",
    "\n",
    "## note that some measures have had name changes in the updated GenerateXML/measures_revised.csv since running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge based \n",
    "plotROC_edge('ROCmetrics/metrics_indirect_groupwise_combinations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on all IC based \n",
    "\n",
    "plotROC_ic('ROCmetrics/metrics_max_indirect_groupwise_combinations.tsv')\n",
    "plotROC_ic('ROCmetrics/metrics_min_indirect_groupwise_combinations.tsv')\n",
    "plotROC_ic('ROCmetrics/metrics_resnik_indirect_groupwise_combinations.tsv')\n",
    "plotROC_ic('ROCmetrics/metrics_sanchez_indirect_groupwise_combinations.tsv')\n",
    "plotROC_ic('ROCmetrics/metrics_seco_indirect_groupwise_combinations.tsv')\n",
    "plotROC_ic('ROCmetrics/metrics_zhou_indirect_groupwise_combinations.tsv')\n",
    "\n",
    "# this was one metric that was run separately due to different requirements \n",
    "plotROC_ic('ROCmetrics/metrics_GIC_indirect_groupwise.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of all AUC scores \n",
    "\n",
    "We can load in all the metrics files and extract the AUC scores to plot the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_AUC(metrics_files):\n",
    "    \n",
    "    ''' input a list of all metrics files in ROCmetrics (or equivalent) folder '''\n",
    "    \n",
    "    auc_scores = pd.DataFrame(columns=['measure', 'AUC']) # to store all AUC scores\n",
    "    \n",
    "    for file in metrics_files:\n",
    "    \n",
    "        data = pd.read_csv('ROCmetrics/{}'.format(file), sep='\\t')\n",
    "\n",
    "        aucs = data.loc[:, ['measure','AUC']]\n",
    "\n",
    "        auc_scores = auc_scores.append(aucs)\n",
    "    \n",
    "    # use a threhsold of 0.5 as some measures give an inverted score (< 0.5)\n",
    "    auc_over_05 = auc_scores.loc[(auc_scores.loc[:, 'AUC'] >= 0.5),:]\n",
    "    auc_under_05 = auc_scores.loc[(auc_scores.loc[:, 'AUC'] < 0.5),:].reset_index(drop=True)\n",
    "    \n",
    "    # for scores under 0.5, represent as 1 - score so all > 0.5\n",
    "    for (i, auc) in enumerate(auc_under_05.loc[:,'AUC']):\n",
    "\n",
    "        auc_under_05.loc[i, 'AUC'] = (1 - auc)\n",
    "    \n",
    "    # rejoin for complete data \n",
    "    auc_scores = auc_over_05.append(auc_under_05)\n",
    "\n",
    "    # calculate quantiles of AUC score distribution\n",
    "    q25 = np.quantile(auc_scores.loc[:, 'AUC'].tolist(), 0.25)\n",
    "    q50 = np.quantile(auc_scores.loc[:, 'AUC'].tolist(), 0.5)\n",
    "    q75 = np.quantile(auc_scores.loc[:, 'AUC'].tolist(), 0.75)\n",
    "    \n",
    "    # plot histogram with quantiles displayed\n",
    "    plt.hist(auc_scores['AUC'], color = 'orange', edgecolor = 'white',\n",
    "             bins = 14) # edit bins as required \n",
    "    plt.title('AUC scores across all measures')\n",
    "    plt.xlabel('AUC')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.vlines(q25, 0, 130, color='red', linestyle='dashed', label='0.25 quantile AUC = %.4f'%q25)\n",
    "    plt.vlines(q50, 0, 115, color='navy', linestyle='dashed', label='0.50 quantile AUC = %.4f'%q50)\n",
    "    plt.vlines(q75, 0, 115, color='darkgreen', linestyle='dashed', label='0.75 quantile AUC = %.4f'%q75)\n",
    "    plt.legend( fontsize='x-small',loc=\"upper right\")\n",
    "\n",
    "    plt.savefig('ROCFigures/hist_AUC.svg')\n",
    "    \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files and run \n",
    "\n",
    "metrics_files = os.listdir('ROCmetrics')\n",
    "\n",
    "hist_AUC(metrics_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of all MRR scores\n",
    "\n",
    "Using same format as above, we can plot a histogram of all MRR scores (NA and zero-based). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_MRR_NA(metrics_files):\n",
    "    \n",
    "    ''' input a list of all metrics files in ROCmetrics (or equivalent) folder '''\n",
    "    \n",
    "    mrr_scores = pd.DataFrame(columns=['measure', 'MRR_NA']) # to store all MRR scores\n",
    "    \n",
    "    for file in metrics_files:\n",
    "    \n",
    "        data = pd.read_csv('ROCmetrics/{}'.format(file), sep='\\t')\n",
    "\n",
    "        mrr = data.loc[:, ['measure','MRR_NA']]\n",
    "\n",
    "        mrr_scores = mrr_scores.append(mrr)\n",
    "    \n",
    "    # calculate quantiles of MRR score distribution\n",
    "    q25 = np.quantile(mrr_scores.loc[:, 'MRR_NA'].tolist(), 0.25)\n",
    "    q50 = np.quantile(mrr_scores.loc[:, 'MRR_NA'].tolist(), 0.5)\n",
    "    q75 = np.quantile(mrr_scores.loc[:, 'MRR_NA'].tolist(), 0.75)\n",
    "    \n",
    "    # plot histogram with quantiles displayed\n",
    "    plt.hist(mrr_scores['MRR_NA'], color = 'cornflowerblue', edgecolor = 'white',\n",
    "             bins = 13) # edit bins as required \n",
    "    plt.title('NaN-based MRR scores across all measures')\n",
    "    plt.xlabel('MRR')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.vlines(q25, 0, 130, color='red', linestyle='dashed', label='0.25 quantile MRR = %.4f'%q25)\n",
    "    plt.vlines(q50, 0, 115, color='navy', linestyle='dashed', label='0.50 quantile MRR = %.4f'%q50)\n",
    "    plt.vlines(q75, 0, 115, color='darkgreen', linestyle='dashed', label='0.75 quantile MRR = %.4f'%q75)\n",
    "    plt.legend( fontsize='x-small',loc=\"upper right\")\n",
    "\n",
    "    plt.savefig('ROCFigures/hist_MRR_NA.svg')\n",
    "    \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files and run \n",
    "\n",
    "metrics_files = os.listdir('ROCmetrics')\n",
    "\n",
    "hist_MRR_NA(metrics_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_MRR_0(metrics_files):\n",
    "    \n",
    "    ''' input a list of all metrics files in ROCmetrics (or equivalent) folder '''\n",
    "    \n",
    "    mrr_scores = pd.DataFrame(columns=['measure', 'MRR_0']) # to store all MRR scores\n",
    "    \n",
    "    for file in metrics_files:\n",
    "    \n",
    "        data = pd.read_csv('ROCmetrics/{}'.format(file), sep='\\t')\n",
    "\n",
    "        mrr = data.loc[:, ['measure','MRR_0']]\n",
    "\n",
    "        mrr_scores = mrr_scores.append(mrr)\n",
    "\n",
    "    # calculate quantiles of MRR score distribution\n",
    "    q25 = np.quantile(mrr_scores.loc[:, 'MRR_0'].tolist(), 0.25)\n",
    "    q50 = np.quantile(mrr_scores.loc[:, 'MRR_0'].tolist(), 0.5)\n",
    "    q75 = np.quantile(mrr_scores.loc[:, 'MRR_0'].tolist(), 0.75)\n",
    "    \n",
    "    # plot histogram with quantiles displayed\n",
    "    plt.hist(mrr_scores['MRR_0'], color = 'mediumturquoise', edgecolor = 'white',\n",
    "             bins = 13) # edit bins as required \n",
    "    plt.title('Zero-based MRR scores across all measures')\n",
    "    plt.xlabel('MRR')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.vlines(q25, 0, 130, color='red', linestyle='dashed', label='0.25 quantile MRR = %.4f'%q25)\n",
    "    plt.vlines(q50, 0, 115, color='navy', linestyle='dashed', label='0.50 quantile MRR = %.4f'%q50)\n",
    "    plt.vlines(q75, 0, 115, color='darkgreen', linestyle='dashed', label='0.75 quantile MRR = %.4f'%q75)\n",
    "    plt.legend( fontsize='x-small',loc=\"upper right\")\n",
    "\n",
    "    plt.savefig('ROCFigures/hist_MRR_0.svg')\n",
    "    \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files and run \n",
    "\n",
    "metrics_files = os.listdir('ROCmetrics')\n",
    "\n",
    "hist_MRR_0(metrics_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of top 10 accuracy\n",
    "\n",
    "Plot the distribution of top 10 accuracy across all scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_top10(metrics_files):\n",
    "    \n",
    "    ''' input a list of all metrics files in ROCmetrics (or equivalent) folder '''\n",
    "    \n",
    "    mrr_scores = pd.DataFrame(columns=['measure', 'Top10_Acc']) # to store all MRR scores\n",
    "    \n",
    "    for file in metrics_files:\n",
    "    \n",
    "        data = pd.read_csv('ROCmetrics/{}'.format(file), sep='\\t')\n",
    "\n",
    "        mrr = data.loc[:, ['measure','Top10_Acc']]\n",
    "\n",
    "        mrr_scores = mrr_scores.append(mrr)\n",
    "\n",
    "    # calculate quantiles of MRR score distribution\n",
    "    q25 = np.quantile(mrr_scores.loc[:, 'Top10_Acc'].tolist(), 0.25)\n",
    "    q50 = np.quantile(mrr_scores.loc[:, 'Top10_Acc'].tolist(), 0.5)\n",
    "    q75 = np.quantile(mrr_scores.loc[:, 'Top10_Acc'].tolist(), 0.75)\n",
    "    \n",
    "    # plot histogram with quantiles displayed\n",
    "    plt.hist(mrr_scores['Top10_Acc'], color = 'coral', edgecolor = 'white',\n",
    "             bins = 12) # edit bins as required \n",
    "    plt.title('Accuracy of the 10 highest scores across all measures')\n",
    "    plt.xlabel('Top 10 accuracy')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.vlines(q25, 0, 130, color='red', linestyle='dashed', label='0.25 quantile top 10 accuracy = %.4f'%q25)\n",
    "    plt.vlines(q50, 0, 115, color='navy', linestyle='dashed', label='0.50 quantile top 10 accuracy = %.4f'%q50)\n",
    "    plt.vlines(q75, 0, 115, color='darkgreen', linestyle='dashed', label='0.75 quantile top 10 accuracy = %.4f'%q75)\n",
    "    plt.legend( fontsize='x-small',loc=\"upper right\")\n",
    "\n",
    "    plt.savefig('ROCFigures/hist_top10.svg')\n",
    "    \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files and run \n",
    "\n",
    "metrics_files = os.listdir('ROCmetrics')\n",
    "\n",
    "hist_top10(metrics_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
